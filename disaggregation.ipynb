{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs: each old geography has an estimate and a margin of error (output from census aggregator), then it has the proportion of the old geography that goes in each of the new geographies\n",
    "\n",
    "\n",
    "Outputs: estimates and margins of error for the new geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "household_income_2013_acs5 = [\n",
    "            \n",
    "        dict( n=900, moe=8)\n",
    "            \n",
    "        ]\n",
    "\n",
    "household_income_la_2013_acs1 = [\n",
    "      \n",
    "      dict( n=1927, moe = 50)\n",
    "  ]\n",
    "\n",
    "\n",
    "test_input = [household_income_2013_acs5,household_income_la_2013_acs1]\n",
    "\n",
    "makeup_1 = [0.8, 0.2] ## 80% of old geography 1 goes to new geography 1, 20% of old geography 1 goes to new geograph 2\n",
    "makeup_2 =  [0.3, 0.7]\n",
    "\n",
    "makeup_input = [makeup_1, makeup_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disaggregate_sum(data_list, makeup, deterministic = True, simulations=50):\n",
    "    \n",
    "    #  if you just want an estimate and ignore margin of error\n",
    "    if deterministic:\n",
    "        results_sum = []\n",
    "        for i in range(len(data_list)):\n",
    "            total = []\n",
    "            results_sum.append([data_list[i][0]['n']*z for z in makeup[i]]) #  get proportion of n going to each new geography\n",
    "        rr = numpy.vstack(results_sum) #  get into array format\n",
    "        est = numpy.apply_along_axis(sum, 0, rr) #  sum each column (total for each new geography)\n",
    "        return est, None\n",
    "    # otherwise deal with margin of error via simulation\n",
    "    else:\n",
    "        simulation_results = []\n",
    "        for s in range(simulations):\n",
    "            results_sum = []\n",
    "            for i in range(len(data_list)):\n",
    "                total = []\n",
    "                se = data_list[i][0]['moe'] / 1.645 #  convert moe to se\n",
    "                new_n = round(numpy.random.normal(data_list[i][0]['n'], se)) # u se moe to introduce randomness into number in bin\n",
    "                new_n = int(new_n) #  clean it up\n",
    "                results_sum.append([new_n*z for z in makeup[i]]) #  get proportion of simulated n going to each new geography\n",
    "            rr = numpy.vstack(results_sum) # get into array format\n",
    "            simulation_results.append(numpy.apply_along_axis(sum, 0, rr)) #  sum each column (total for each new geography)\n",
    "        ss = numpy.vstack(simulation_results) #  get simulation into array format\n",
    "        est = numpy.apply_along_axis(numpy.mean, 0, ss) #  mean across simulations\n",
    "        t1 = numpy.apply_along_axis(numpy.quantile, axis=0, arr =ss, q=0.95) - est #  higher quantile across simulations\n",
    "        t2 = est - numpy.apply_along_axis(numpy.quantile, axis=0, arr = ss, q=0.05) #  lower quantile across simulations\n",
    "        margin_of_error = numpy.amax(numpy.column_stack((t1,t2)), 1) #  take the larger of each row to be conservative\n",
    "        return est, margin_of_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1298.1, 1528.9]), None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaggregate_sum(test_input, makeup_input, deterministic = True, simulations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1298.502, 1528.938]), array([13.933, 27.603]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaggregate_sum(test_input, makeup_input, deterministic = False, simulations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disaggregate_mean(data_list, makeup, deterministic = True, simulations=50):\n",
    "    #  if you just want an estimate and ignore margin of error\n",
    "    if deterministic:\n",
    "        denom = disaggregate_sum(data_list, makeup, deterministic = True, simulations=50)[0] #  get the weighted sum for denominator of weighted mean\n",
    "        results = []\n",
    "        grand_total = []\n",
    "        for i in range(len(data_list)):\n",
    "            total = data_list[i][0]['n'] * data_list[i][0]['val'] #  weighted value\n",
    "            results.append([total*z for z in makeup[i]])  #  partition by new geograph\n",
    "        rr = numpy.vstack(results) #  get in array format\n",
    "        rr2 = numpy.apply_along_axis(sum, 0, rr) #  weighted sum\n",
    "        est = numpy.divide(rr2, denom) #  get the weighted average\n",
    "        return est, None\n",
    "    #  otherwise deal with margin of error via simulation\n",
    "    else:\n",
    "        #  have to redo simulation can't just use sum call because randomness won't match up\n",
    "        simulation_results = [] #  weighted sum\n",
    "        simulation_results_v = [] #  weighted sum and values\n",
    "        for s in range(simulations):\n",
    "            results = [] #   intermediate weighted sum\n",
    "            results_v = [] #  intermediate weighted sum and values\n",
    "            for i in range(len(data_list)):\n",
    "                se = data_list[i][0]['moe'] / 1.645 #  convert moe to se\n",
    "                new_n = round(numpy.random.normal(data_list[i][0]['n'], se))\n",
    "                #  use moe to introduce randomness into number in bin\n",
    "                new_n = int(new_n) #  clean it up\n",
    "                results.append([new_n * z for z in makeup[i]]) \n",
    "                results_v.append([new_n * data_list[i][0]['val']*z  for z in makeup[i]])\n",
    "            rr = numpy.vstack(results) #  get results into array format\n",
    "            rr_v = numpy.vstack(results_v) #  get results into array format\n",
    "            simulation_results.append(numpy.apply_along_axis(sum, 0, rr)) #  do sum for numerator of weighted mean\n",
    "            simulation_results_v.append(numpy.apply_along_axis(sum, 0, rr_v)) #  do sum for denominator of weighted mean\n",
    "        ss = numpy.vstack(simulation_results) #  get simulation into array format\n",
    "        ss_v = numpy.vstack(simulation_results_v) #  get simulation into array format\n",
    "        ssd = numpy.divide(ss_v, ss) #  get weighted mean\n",
    "        est = numpy.apply_along_axis(numpy.mean, 0, ssd) #  take mean of weighted means across simulations\n",
    "        t1 = numpy.apply_along_axis(numpy.quantile, axis=0, arr =ssd, q=0.95) - est #  upper quantile of weighted means across simulations\n",
    "        t2 = est - numpy.apply_along_axis(numpy.quantile, axis=0, arr = ssd, q=0.05) #  lower quantile of weighted means across simulations\n",
    "        margin_of_error = numpy.amax(numpy.column_stack((t1,t2)), 1) #  take max across rows to be conservative\n",
    "        return est, margin_of_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_2013_acs5 = [\n",
    "            \n",
    "            dict( val=34999, n=900, moe=8)\n",
    "            \n",
    "        ]\n",
    "\n",
    "household_income_la_2013_acs1 = [\n",
    "      \n",
    "      dict( val=49929, n=1757, moe = 50)\n",
    "  ]\n",
    "\n",
    "\n",
    "test_input = [household_income_2013_acs5,household_income_la_2013_acs1]\n",
    "\n",
    "makeup_1 = [0.8, 0.2]\n",
    "makeup_2 =  [0.3, 0.7]\n",
    "\n",
    "makeup_input = [makeup_1, makeup_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([41309.32234785, 48022.90736932]), None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaggregate_mean(test_input, makeup_input, deterministic = True, simulations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([41311.78934568, 48023.90355135]), array([61.01254397, 27.74911393]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaggregate_mean(test_input, makeup_input, deterministic = False, simulations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
